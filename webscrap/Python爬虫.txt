************************************************************************************************************************************
之前整理资料：
主题一：爬虫步骤：
1、如何生成url地址：
   http://money.finance.sina.com.cn/corp/go.php/vFD_BalanceSheet/stockid/600660/ctrl/2017/displaytype/4.phtml
   只需要替换股票代码（600660）和年份（2017）两个字段，就可以生成其他股票或年份的数据
2、利用requeset爬取页面源码
   用法：requests.get(url,headers = headers)
   其中，url为访问地址；headers用于设置代理，页面支持的代理可以去网站查找
3、如何筛选出有用的数据
 1）推荐工具：BeautifulSoup（很方便地提取出HTML或XML标签中的内容）
    用法：soup.select('table#ProfitStatementNewTable0')，其中table#ProfitStatementNewTable0，为源码中某个表的ID
    同时，BeautifulSoup支持Xpath定位，有兴趣可以自己百度
    网址：https://cuiqingcai.com/1319.html
 2）正则表达式：通用但是要学习其使用方法，入门的门槛较高，不如BeautifulSoup简单易学
    用法：re.findall('正则表达式'，页面源码)
    学习网址：https://www.cnblogs.com/chuxiuhong/p/5885073.html
4、利用pandas输出并存储数据(csv文档)
    用法：pd.DataFrame(data, index=dates, columns= features)
    data：表的内容（二维矩阵）
    index:索引值，比如说爬虫的某个股票2017年的数据，索引值为日期
    columns：表头，列的名称


2018.4.2
1、如何查看robot.txt：只需要在地址后面加/robot.txt即可

************************************************************************************************************************************
2018.4.6
---------------
1、Python2中的urllib、urllib2与Python3中的urllib以及第三方模块requests
   参考资料：https://blog.csdn.net/Goldxwang/article/details/76850401
   结论：Requests 是用Python语言编写，基于 urllib，采用 Apache2 Licensed 开源协议的 HTTP 库。它比 urllib 更加方便，可以节约我们大量的工作，完全满足 HTTP 测试需求。Requests 的哲学是以 PEP 20 的习语为中心开发的，所以它比 urllib 更加 Pythoner。更重要的一点是它支持 Python3 哦！
2、request参考资料：https://blog.csdn.net/lihao21/article/details/51857385


************************************************************************************************************************************
2018.4.6
---------------
一、解决动态页面爬取问题
https://blog.csdn.net/qq_30242609/article/details/53788228
二：python将str保存问txt文档
def save_to_file(file_name, contents):
    fh = open(file_name, 'w')
    fh.write(contents)
    fh.close()
二、python与正则表达式
两个问题：
1、正则表达式转移字符\
参考资料：https://www.cnblogs.com/ajianbeyourself/p/5709567.html
2、如何解决正则表达式的贪婪问题
参考资料：
默认是贪婪模式；在量词后面直接加上一个问号？就是非贪婪模式。
量词：{M,N} :最少M个，最多N个
*：任意多个
+：一个到多个
？：0或一个
三：beatifulSoup基本用法
参考文档：https://blog.csdn.net/kikaylee/article/details/56841789
四：pytho与正则表达式
正则表达式基础教程：http://www.runoob.com/regexp/regexp-operator.html
python正则表达式：http://www.runoob.com/python/python-reg-expressions.html
五：批量下载pdf
参考资料：https://blog.csdn.net/u012705410/article/details/47708031
六：关于字符串：python路径中最好是用/代替\，字符串最后为\会报错


-------------
整体思路：
1、获取所有月份下的pdf地址


************************************************************************************************************************************
2018.4.8
------------------------------------------
1、str为不可变类，b=a.replace(',','')






